{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OVdLWpCU58db"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# constants:\n",
        "k_dim = 20\n",
        "gamma = 2"
      ],
      "metadata": {
        "id": "tglWeXxuxZ3i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "hct_XwFM0FSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee3a491-09b4-4c6d-dea4-2730f003756e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are working with several categories of objects. First of all we have the database:\n",
        "$$D = \\{(e^l, r, e^r)\\} \\subseteq E \\times R \\times E =: \\Omega$$\n",
        "where $e^l, e^r$'s are entities and $r$'s are relations, $E, R$ are sets of them. Second of all we are training our model that is concerned with vectors:\n",
        "$$\\overline{e^l}, \\overline{e^r}, \\overline{r} \\in \\mathbb{R}^k.$$\n",
        "\n",
        "Our main object is a triple $s = (e^l, r, e^r)$ for which we define its loss to be\n",
        "$$l(s) = relu (\\gamma + \\mathbb{1}_D\\cdot ||\\overline{e^l}+ \\overline{e^r}- \\overline{r}|| - \\mathbb{1}_{\\Omega \\backslash D}\\cdot ||\\overline{e^l}+ \\overline{e^r}- \\overline{r}||)$$\n",
        "\n",
        "(where $\\gamma$ is some pre-defined margin).\n",
        "\n",
        "If we put $\\overline{D} = D \\cup \\{(e^l, r, e^r) \\; : \\; e^l \\in D \\vee e^r \\in D\\}$ the overall loss will be \n",
        "$$\\mathcal{L} = \\sum_{s \\in \\overline{D}} l(s)$$"
      ],
      "metadata": {
        "id": "gofhUn4sX-eO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua6krB0y6ZgX",
        "outputId": "7ad37db1-ce0c-4ecc-827c-c05ee7e4a07d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9122, 0.1428, 0.1529, 0.2793, 0.6300, 0.3247, 0.0249, 0.6887, 0.7007,\n",
            "        0.0142, 0.1191, 0.0099, 0.5673, 0.9276, 0.5176, 0.3062, 0.6451, 0.4297,\n",
            "        0.9711, 0.5383], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# reading dataset and extracting sets of entities, relations. \n",
        "''' \n",
        "datastructure here is following:\n",
        "we store rel-s in a dictionary with keys being \"name1 name2\" and \n",
        "values being sets of relations between name1 and name2\n",
        "\n",
        "here we also initialize values that we'll use later for the model\n",
        "'''\n",
        "\n",
        "\n",
        "f = open('/content/drive/MyDrive/MLDL/Release/train.txt', \"r\")\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# f = open('/train.txt', 'r')\n",
        "\n",
        "dataset = {}\n",
        "ent_vect = {}\n",
        "rel_vect = {}\n",
        "\n",
        "while True:\n",
        "  line = f.readline()\n",
        "  mas = line.split('\\t')\n",
        "  if len(mas) ==3 :\n",
        "    ent_l = line.split('\\t')[0]\n",
        "    rel = line.split('\\t')[1]\n",
        "\n",
        "    r = line.split('\\t')[2]\n",
        "    ent_r = r[:len(r)-1]\n",
        "    # print(ent_l + \" \" + ent_r)\n",
        "\n",
        "    val_dat = dataset.get(ent_l + \" \" + ent_r, -100)\n",
        "    val_ent_l = ent_vect.get(ent_l, \"lol\")\n",
        "    val_ent_r = ent_vect.get(ent_r, \"lol\")\n",
        "    val_rel = rel_vect.get(rel, \"lol\")\n",
        "\n",
        "    if val_dat != -100:\n",
        "      dataset[ent_l + \" \" + ent_r].add(rel)\n",
        "    else:\n",
        "      dataset.update({ent_l + \" \" + ent_r : {rel} })\n",
        "\n",
        "    if val_ent_l == \"lol\":\n",
        "      a = torch.rand(k_dim, device = device)\n",
        "      ent_vect[ent_l] = a\n",
        "\n",
        "    if val_ent_r == \"lol\":\n",
        "      a = torch.rand(k_dim, device = device)\n",
        "      ent_vect[ent_r] = a\n",
        "\n",
        "    if val_rel == \"lol\":\n",
        "      a = torch.rand(k_dim, device = device)\n",
        "      rel_vect[rel] = a\n",
        "  else:\n",
        "      break\n",
        "# print(rel_vect['/tv/tv_program/regular_cast./tv/regular_tv_appearance/actor']) #checking that everything's OK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "\n",
        "''' \n",
        "dataset = {} -- consists of      [num_1, num_2, relations(num_1, num_2)    ]\n",
        "\n",
        "ent_vect = {} -- consists of      [entity, vector],   vectors initialized to be random \n",
        "\n",
        "rel_vect = {} -- consists of      [relation, vector],   vectors initialized to be random \n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "psC5Ivjooz_L",
        "outputId": "07321076-cfb9-4140-a82c-79c9731332e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\ndataset = {} -- consists of      [num_1, num_2, relations(num_1, num_2)    ]\\n\\nent_vect = {} -- consists of      [entity, vector],   vectors initialized to be random \\n\\nrel_vect = {} -- consists of      [relation, vector],   vectors initialized to be random \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return max(x, 0)\n",
        "def dist(x,y):\n",
        "  return math.sqrt((x-y)@torch.transpose(x-y))"
      ],
      "metadata": {
        "id": "K83QZSq72VKO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def making_batch(size_b, limit_counter = 15): #benedict minibatch\n",
        "  out = []\n",
        "  k = 0\n",
        "  while k < size_b:\n",
        "    name, rels = random.choice(list(dataset.items())) # choosing random pair of entities\n",
        "\n",
        "    rel = random.choice(list(rels)) # choosing random relation between them \n",
        "\n",
        "    [e1, e2] = name.split() #names of these relations\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    while counter < limit_counter:\n",
        "      a = random.randint(1,2)\n",
        "      ent, _ = random.choice(list(ent_vect.items()))\n",
        "      if a == 1:\n",
        "        v = (ent + \" \" + e2)\n",
        "      else: \n",
        "        v = (e1 + \" \" + ent)\n",
        "\n",
        "      if dataset.get(v, \"lol\") != \"lol\":\n",
        "        if not (rel in  dataset[v]):\n",
        "          k+=1\n",
        "          if a == 1:\n",
        "            out.append(((e1, rel, e2), (ent, rel, e2)))\n",
        "            continue\n",
        "          else:\n",
        "            out.append(((e1, rel, e2),(e1, rel, ent)))\n",
        "            continue\n",
        "      counter+=1\n",
        "  return out\n",
        "\n",
        "# a = making_batch(3)\n",
        "# print(a)"
      ],
      "metadata": {
        "id": "yQmVdUPq4XTF"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_true(size_b):\n",
        "  out = []\n",
        "  for _ in range(size_b):\n",
        "    name, rels = random.choice(list(dataset.items()))\n",
        "    rel = random.choice(list(rels))\n",
        "    [ent1, ent2] = name.split()\n",
        "    out.append((ent1, rel, ent2))\n",
        "  return out\n",
        "\n",
        "def error(e1, r, e2):\n",
        "  return dist(ent_vect[e1]+rel_vect[r], ent_vect[e2])\n",
        "\n",
        "def find_cor(e1, r, e2, flag): #another function that samples a corrupted triplet for a given one\n",
        "  counter = 0\n",
        "  while (True):\n",
        "    ent, _ = random.choice(list(ent_vect.items()))\n",
        "    # print(ent)\n",
        "    if flag == 1:\n",
        "      v = (ent + \" \" + e2)\n",
        "    else:\n",
        "      v = (e1 + \" \" + ent)\n",
        "    \n",
        "    if dataset.get(v, \"lol\") != \"lol\":\n",
        "      if not (r in  dataset[v]):\n",
        "        if flag == 1:\n",
        "          return (ent, r, e2)\n",
        "        else:\n",
        "          return (e1, r, ent)\n",
        "      # else:\n",
        "        # print(ent, r, e2)\n",
        "    \n",
        "# print(find_cor(\"/m/017dcd\", \"/tv/tv_program/regular_cast./tv/regular_tv_appearance/actor\", \"/m/06v8s0\", 2)) #testing\n",
        "  \n",
        "def corrupted_loss(e1, r, e2): #loss for a single point\n",
        "\n",
        "  a = random.randint(1,2) #use it here to make \"corruption\"\n",
        "                          #on one of two ends without decision making\n",
        "  corr = find_cor(e1,r,e2,a)\n",
        "  el_ = corr[0]\n",
        "  r_ = corr[1]\n",
        "  er_ = corr[2]\n",
        "  return relu(gamma + error(e1, r, e2) - error(el_, r_, er_))"
      ],
      "metadata": {
        "id": "HfmnbcmSnhJF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZlUsvtvsF6Y",
        "outputId": "eadbd282-185b-4e1c-c9b0-63c451aea08a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 26 20:57:05 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    28W /  70W |    579MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here are some additional functions to utilize while training\n",
        "\n",
        "def norming():\n",
        "  for name in ent_vect:\n",
        "    x = ent_vect[name]\n",
        "    ent_vect[name] = x / torch.norm(x)\n",
        "\n",
        "lam = 0.01 #learning rate\n",
        "def update(batch): #function that updates vectors\n",
        "  for true_val in batch:\n",
        "    a = random.randint(1,2)\n",
        "\n",
        "    pair = find_cor(true_val[0], true_val[1], true_val[2], a)\n",
        "\n",
        "    ent_vect[true_val[0]] += lam*2*(ent_vect[true_val[0]] + rel_vect[true_val[1]] - ent_vect[true_val[2]])\n",
        "    ent_vect[true_val[2]] -= lam*2*(ent_vect[true_val[0]] + rel_vect[true_val[1]] - ent_vect[true_val[2]])\n",
        "    rel_vect[true_val[1]] += lam*2*(ent_vect[true_val[0]] + rel_vect[true_val[1]] - ent_vect[true_val[2]])\n",
        "\n",
        "    ent_vect[true_val[0]] -= lam*2*(ent_vect[pair[0]] + rel_vect[pair[1]] - ent_vect[pair[2]])\n",
        "    rel_vect[true_val[1]] += lam*2*(ent_vect[pair[0]] + rel_vect[pair[1]] - ent_vect[pair[2]])\n",
        "    ent_vect[true_val[2]] -= lam*2*(ent_vect[pair[0]] + rel_vect[pair[1]] - ent_vect[pair[2]])\n",
        "\n",
        "def alt_upd (batch): #function that updates vectors in another way\n",
        "  for true_val in batch:\n",
        "    e1 = true_val[0][0].strip()\n",
        "    e2 = true_val[0][2].strip()\n",
        "    r = true_val[0][1].strip()\n",
        "\n",
        "    e1_ = true_val[1][0].strip()\n",
        "    e2_ = true_val[1][2].strip()\n",
        "    r_ = true_val[1][1].strip()\n",
        "\n",
        "    shift_1 = lam*2*(ent_vect[e1] + rel_vect[r] - ent_vect[e2])\n",
        "\n",
        "    ent_vect[e1] += shift_1\n",
        "    ent_vect[e2] -= shift_1\n",
        "    rel_vect[r] += shift_1\n",
        "\n",
        "    shift_2 = lam*2*(ent_vect[e1_] + rel_vect[r_] - ent_vect[e2_])\n",
        "\n",
        "    ent_vect[e1] -= shift_2\n",
        "    rel_vect[r] += shift_2\n",
        "    ent_vect[e2] -= shift_2"
      ],
      "metadata": {
        "id": "P1wzlCkUb4va"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#article update: \n",
        "\n",
        "n_iter = 1\n",
        "size_b = 10\n",
        "\n",
        "for _ in range(n_iter):\n",
        "  print(_)\n",
        "  norming()\n",
        "  batch = batch_true(size_b)\n",
        "  update(batch)"
      ],
      "metadata": {
        "id": "PlZyrwTt8cFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative update:\n",
        "\n",
        "n_iter = 10\n",
        "size_b = 10\n",
        "\n",
        "for _ in range(n_iter):\n",
        "  print(_)\n",
        "  norming()\n",
        "  batch = making_batch(size_b)\n",
        "  alt_upd(batch)"
      ],
      "metadata": {
        "id": "1MGlcvaKQTU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(ent_vect)\n",
        "# print(rel_vect)"
      ],
      "metadata": {
        "id": "F1VYpSjrWxIm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}